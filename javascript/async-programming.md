# JavaScript Asynchronous Programming - T·ª´ L√Ω Thuy·∫øt ƒê·∫øn Th·ª±c Chi·∫øn

> **M·ª•c ti√™u**: Hi·ªÉu s√¢u v·ªÅ c∆° ch·∫ø b·∫•t ƒë·ªìng b·ªô trong JavaScript t·ª´ internals ƒë·∫øn production patterns, v·ªõi focus v√†o practical applications v√† performance.

---

## üìö Table of Contents

1. [Event Loop Architecture](#1-event-loop-architecture)
2. [Microtask vs Macrotask - Ph√¢n Bi·ªát & ·ª®ng D·ª•ng](#2-microtask-vs-macrotask---ph√¢n-bi·ªát--·ª©ng-d·ª•ng)
3. [Promises - Internals & Production Patterns](#3-promises---internals--production-patterns)
4. [Async/Await - Advanced Techniques](#4-asyncawait---advanced-techniques)
5. [Advanced Async Patterns](#5-advanced-async-patterns)
6. [Async Iteration & Generators](#6-async-iteration--generators)
7. [Error Handling in Production](#7-error-handling-in-production)
8. [Performance Optimization](#8-performance-optimization)
9. [Testing Async Code](#9-testing-async-code)
10. [Production Best Practices](#10-production-best-practices)

---

## 1. Event Loop Architecture

### 1.1. T·∫°i Sao JavaScript C·∫ßn Event Loop?

**V·∫•n ƒë·ªÅ c·ªët l√µi**: JavaScript ch·∫°y tr√™n m√¥ h√¨nh **single-threaded** (ƒë∆°n lu·ªìng), nh∆∞ng ph·∫£i x·ª≠ l√Ω ƒë·ªìng th·ªùi nhi·ªÅu t√°c v·ª•:
- T∆∞∆°ng t√°c ng∆∞·ªùi d√πng (clicks, scrolls, keyboard input)
- Network I/O (fetch API, XMLHttpRequest)
- Timers (setTimeout, setInterval, requestAnimationFrame)
- File system operations (Node.js fs module, File API)
- DOM rendering v√† layout calculations

**V·∫•n ƒë·ªÅ n·∫øu ch·∫°y tu·∫ßn t·ª±**: B·∫•t k·ª≥ **long-running synchronous operations** (CPU-intensive tasks, synchronous I/O, blocking loops) ƒë·ªÅu block main thread, d·∫´n ƒë·∫øn UI lag nghi√™m tr·ªçng v·ªõi frame drops d∆∞·ªõi 60 FPS.

**Gi·∫£i ph√°p ki·∫øn tr√∫c**: Event Loop ƒëi·ªÅu ph·ªëi execution model b·∫•t ƒë·ªìng b·ªô, offload I/O operations sang OS-level async APIs v√† CPU-intensive tasks sang Web Workers.

### 1.2. Ki·∫øn Tr√∫c Runtime c·ªßa JavaScript

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   JavaScript Engine       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ    Call Stack       ‚îÇ  ‚îÇ  (LIFO - th·ª±c thi synchronous code)
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ    Memory Heap      ‚îÇ  ‚îÇ  (Dynamic allocation)
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Browser/Node APIs       ‚îÇ
‚îÇ  - setTimeout             ‚îÇ
‚îÇ  - fetch                  ‚îÇ
‚îÇ  - DOM Events             ‚îÇ
‚îÇ  - File I/O (Node)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Microtask Queue          ‚îÇ ‚Üê ƒê·ªô ∆∞u ti√™n CAO
‚îÇ  - Promise.then/catch     ‚îÇ
‚îÇ  - queueMicrotask()       ‚îÇ
‚îÇ  - MutationObserver       ‚îÇ
‚îÇ  - process.nextTick()     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Macrotask Queue          ‚îÇ ‚Üê ƒê·ªô ∆∞u ti√™n TH·∫§P
‚îÇ  (Task Queue)             ‚îÇ
‚îÇ  - setTimeout             ‚îÇ
‚îÇ  - setInterval            ‚îÇ
‚îÇ  - setImmediate           ‚îÇ
‚îÇ  - I/O callbacks          ‚îÇ
‚îÇ  - UI rendering           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ  Event Loop  ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**3 th√†nh ph·∫ßn ch√≠nh**:

1. **JavaScript Engine** (V8, SpiderMonkey, JavaScriptCore):
   - **Call Stack**: C·∫•u tr√∫c LIFO qu·∫£n l√Ω execution contexts, x·ª≠ l√Ω c√°c operations ƒë·ªìng b·ªô tu·∫ßn t·ª±
   - **Memory Heap**: V√πng nh·ªõ non-contiguous cho dynamic object allocation, ƒë∆∞·ª£c qu·∫£n l√Ω b·ªüi garbage collector

2. **Web APIs / Node.js C++ Bindings**:
   - **Browser Runtime**: DOM APIs, Fetch API, Timer APIs, IndexedDB, WebCrypto
   - **Node.js Runtime**: libuv-backed modules (fs, http, crypto), native timers
   - **Nguy√™n l√Ω quan tr·ªçng**: Offload I/O operations sang OS-level async APIs, gi·∫£i ph√≥ng main thread

3. **Event Loop**:
   - **C∆° ch·∫ø ƒëi·ªÅu ph·ªëi**: Li√™n t·ª•c monitor call stack v√† task queues, orchestrate task execution
   - **Thu·∫≠t to√°n scheduling**: ∆Øu ti√™n microtasks tr∆∞·ªõc macrotasks, ƒë·∫£m b·∫£o execution order x√°c ƒë·ªãnh
   - **Performance characteristic**: ~1ms m·ªói iteration trong ƒëi·ªÅu ki·ªán b√¨nh th∆∞·ªùng

### 1.3. T·∫°i Sao C√≥ 2 Lo·∫°i Queues?

#### 1Ô∏è‚É£ Microtask Queue ‚Üí High-Priority Atomic Operations

**ƒê·∫∑c ƒëi·ªÉm th·ª±c thi**:
- **ƒê·∫£m b·∫£o ho√†n th√†nh nguy√™n t·ª≠**: T·∫•t c·∫£ microtasks trong queue ƒë∆∞·ª£c th·ª±c thi tu·∫ßn t·ª± tr∆∞·ªõc khi yield control cho browser rendering ho·∫∑c macrotask processing
- **Use cases ch√≠nh**:
  - Promise resolution/rejection callbacks (.then, .catch, .finally)
  - Async function continuation sau await points
  - Framework internal state reconciliation (Virtual DOM diffing)
  - MutationObserver callbacks
  - queueMicrotask() API

**L√Ω do th·ª±c thi theo batch**:
- **T√≠nh nh·∫•t qu√°n state**: NgƒÉn intermediate UI states b·ªã render trong qu√° tr√¨nh multi-step state transitions
- **T·ªëi ∆∞u rendering**: Gi·∫£m layout thrashing kh√¥ng c·∫ßn thi·∫øt b·∫±ng c√°ch batch DOM reads/writes
- **Performance impact**: Ch·ªâ invoke render pipeline m·ªôt l·∫ßn thay v√¨ nhi·ªÅu l·∫ßn partial renders
- **V√≠ d·ª•**: React batch state updates trong event handlers ƒë·ªÉ trigger single re-render

**√ù nghƒ©a quan tr·ªçng**: Microtask queue ph·∫£i complete atomically ƒë·ªÉ duy tr√¨ synchronous appearance c·ªßa JavaScript trong async boundaries.

#### 2Ô∏è‚É£ Macrotask Queue ‚Üí Deferrable Scheduled Work

**ƒê·∫∑c ƒëi·ªÉm th·ª±c thi**:
- **Single-Task-Per-Tick**: Event loop x·ª≠ l√Ω ƒë√∫ng m·ªôt macrotask m·ªói iteration, sau ƒë√≥ yield control
- **Interleaving Points**: Browser c√≥ th·ªÉ execute rendering pipeline gi·ªØa c√°c macrotasks:
  - Style calculation v√† layout (Recalc Style/Layout trong DevTools)
  - Paint v√† composite operations
  - User input event processing
  - requestAnimationFrame callbacks

**L√Ω do thi·∫øt k·∫ø**:
- **NgƒÉn main thread starvation**: ƒê·∫£m b·∫£o browser responsiveness b·∫±ng c√°ch gi·ªõi h·∫°n continuous JavaScript execution
- **B·∫£o to√†n rendering budget**: Duy tr√¨ 60 FPS target b·∫±ng c√°ch gi·ªØ frame budget d∆∞·ªõi ~16.67ms
- **Input responsiveness**: Cho ph√©p x·ª≠ l√Ω user interactions trong 100ms RAIL threshold
- **V√≠ d·ª•**: setTimeout callbacks execute t·ª´ng c√°i m·ªôt, v·ªõi render opportunities gi·ªØa m·ªói callback

**Ngu·ªìn macrotask ph·ªï bi·∫øn**: setTimeout, setInterval, setImmediate (Node.js), I/O callbacks, UI events

#### üéØ T√≥m t·∫Øt ∆Øu ti√™n Queue:
```
Microtasks: Atomic batch execution, high priority, state-critical operations
Macrotasks: Singular execution v·ªõi yield points, cho ph√©p rendering interleaving
```

> **‚ö†Ô∏è L∆∞u √Ω quan tr·ªçng**: Microtask Queue v√† Macrotask Queue l√† **hai h√†ng ƒë·ª£i ho√†n to√†n t√°ch bi·ªát**, kh√¥ng ph·∫£i c√πng n·∫±m trong m·ªôt "Task Queues". Event Loop s·∫Ω ∆∞u ti√™n x·ª≠ l√Ω **T·∫§T C·∫¢** microtasks tr∆∞·ªõc khi chuy·ªÉn sang b·∫•t k·ª≥ macrotask n√†o.

### 1.4. Event Loop Ho·∫°t ƒê·ªông Nh∆∞ Th·∫ø N√†o?

Event Loop l√† m·ªôt **v√≤ng l·∫∑p v√¥ h·∫°n** li√™n t·ª•c ki·ªÉm tra v√† th·ª±c thi c√°c task theo th·ª© t·ª± ∆∞u ti√™n:

```javascript
// Pseudocode c·ªßa Event Loop
while (true) {
  // 1. Ki·ªÉm tra Call Stack c√≥ r·ªóng kh√¥ng?
  if (callStack.isEmpty()) {
    
    // 2. ∆Øu ti√™n x·ª≠ l√Ω T·∫§T C·∫¢ Microtasks tr∆∞·ªõc
    while (microtaskQueue.hasTask()) {
      const microtask = microtaskQueue.dequeue();
      callStack.push(microtask);
      execute(microtask);
    }
    
    // 3. Sau ƒë√≥ m·ªõi x·ª≠ l√Ω M·ªòT Macrotask
    if (macrotaskQueue.hasTask()) {
      const macrotask = macrotaskQueue.dequeue();
      callStack.push(macrotask);
      execute(macrotask);
    }
    
    // 4. Render UI (n·∫øu c·∫ßn - trong browser)
    if (needsRendering) {
      renderUI();
    }
  }
}
```

### 1.5. Event Loop Phases (Node.js)

Node.js Event Loop c√≥ **6 phases**:

```
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îå‚îÄ>‚îÇ        timers         ‚îÇ  setTimeout, setInterval
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚îÇ  pending callbacks    ‚îÇ  I/O callbacks t·ª´ previous iteration
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚îÇ    idle, prepare      ‚îÇ  Internal use only
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚îÇ        poll           ‚îÇ  Retrieve I/O events, execute callbacks
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚îÇ        check          ‚îÇ  setImmediate callbacks
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îî‚îÄ‚îÄ‚îÇ   close callbacks     ‚îÇ  socket.on('close', ...)
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Gi·ªØa m·ªói phase**: Process **T·∫§T C·∫¢** Microtasks

### 1.6. V√≠ D·ª• Minh H·ªça Event Loop

#### V√≠ d·ª• c∆° b·∫£n:

```javascript
console.log('1: Script start');

setTimeout(() => {
  console.log('2: setTimeout');
}, 0);

Promise.resolve()
  .then(() => {
    console.log('3: Promise 1');
  })
  .then(() => {
    console.log('4: Promise 2');
  });

console.log('5: Script end');

// Output:
// 1: Script start
// 5: Script end
// 3: Promise 1
// 4: Promise 2
// 2: setTimeout
```

**Gi·∫£i th√≠ch t·ª´ng b∆∞·ªõc**:
1. "1: Script start" - Synchronous code, ch·∫°y ngay l·∫≠p t·ª©c
2. setTimeout - ƒê∆∞·ª£c ƒë∆∞a v√†o **Macrotask Queue**
3. Promise.resolve().then() - ƒê∆∞·ª£c ƒë∆∞a v√†o **Microtask Queue**
4. "5: Script end" - Synchronous code, ch·∫°y ngay l·∫≠p t·ª©c
5. Call Stack r·ªóng ‚Üí Event Loop ki·ªÉm tra
6. **Microtask Queue** ƒë∆∞·ª£c x·ª≠ l√Ω tr∆∞·ªõc ‚Üí "3: Promise 1", "4: Promise 2"
7. **Macrotask Queue** ƒë∆∞·ª£c x·ª≠ l√Ω sau ‚Üí "2: setTimeout"

#### V√≠ d·ª• ph·ª©c t·∫°p h∆°n:

```javascript
console.log('Start');

setTimeout(() => {
  console.log('Timeout 1');
  Promise.resolve().then(() => console.log('Promise in Timeout 1'));
}, 0);

Promise.resolve()
  .then(() => {
    console.log('Promise 1');
    setTimeout(() => console.log('Timeout in Promise 1'), 0);
  })
  .then(() => {
    console.log('Promise 2');
  });

setTimeout(() => {
  console.log('Timeout 2');
}, 0);

console.log('End');

// Output:
// Start
// End
// Promise 1
// Promise 2
// Timeout 1
// Promise in Timeout 1
// Timeout in Promise 1
// Timeout 2
```

### 1.7. Real-World Use Cases

#### **Use Case 1: Batching DOM Updates ƒë·ªÉ T·ªëi ∆∞u Rendering**

**V·∫•n ƒë·ªÅ**: State updates ƒë·ªìng b·ªô naive trigger cascading re-renders
```
setState() ‚Üí commit phase ‚Üí layout ‚Üí paint (16ms)
setState() ‚Üí commit phase ‚Üí layout ‚Üí paint (16ms)  
setState() ‚Üí commit phase ‚Üí layout ‚Üí paint (16ms)
T·ªïng: 48ms, 3 frame drops t·∫°i 60 FPS
```

**Gi·∫£i ph√°p**: Microtask-based update batching (React 18 Automatic Batching)
```
setState() ‚Üí schedule microtask (defer reconciliation)
setState() ‚Üí coalesce v√†o pending batch
setState() ‚Üí coalesce v√†o pending batch
‚Üí Single commit phase sau khi microtask queue drain
T·ªïng: ~16ms, zero frame drops
```

**Performance Gain**: Gi·∫£m 3x render overhead th√¥ng qua batch reconciliation

#### **Use Case 2: X·ª≠ L√Ω Race Condition trong Search Autocomplete**

**Scenario**: Chu·ªói keystroke nhanh t·∫°o ra concurrent requests
- Keystroke "h" ‚Üí Request A (network latency: 150ms)
- Keystroke "he" ‚Üí Request B (network latency: 100ms)
- Keystroke "hel" ‚Üí Request C (network latency: 80ms)

**V·∫•n ƒë·ªÅ**: Th·ª© t·ª± complete non-deterministic vi ph·∫°m result freshness invariant
- Request C complete tr∆∞·ªõc (k·∫øt qu·∫£ ƒë√∫ng cho "hel")
- Request A complete cu·ªëi (stale results cho "h" override UI ƒë√∫ng)

**Chi·∫øn l∆∞·ª£c gi·∫£i quy·∫øt**:
1. **AbortController Pattern**: Cancel in-flight requests khi query m·ªõi ƒë∆∞·ª£c issue (preferred)
2. **Request Token Validation**: Discard responses kh√¥ng match latest query ID
3. **Debounced Dispatch**: Defer request ƒë·∫øn khi 300ms idle period (gi·∫£m request volume)

#### **Use Case 3: Long Task Chunking ƒë·ªÉ Duy Tr√¨ Responsiveness**

**V·∫•n ƒë·ªÅ**: X·ª≠ l√Ω 1M records ƒë·ªìng b·ªô blocks main thread trong 5000ms
- Frame budget t·∫°i 60 FPS: 16.67ms
- 5000ms blockage = 300 dropped frames
- Time to Interactive (TTI): Severely degraded

**Gi·∫£i ph√°p**: Time-slicing v·ªõi macrotask scheduling
```javascript
// Chunk size: 10K items √ó 5ms processing = 50ms per chunk
// T·ªïng chunks: 100
// Yield points: 99 (setTimeout gi·ªØa c√°c chunks)

async function processLargeDataset(items) {
  const chunkSize = 10000;
  
  for (let i = 0; i < items.length; i += chunkSize) {
    const chunk = items.slice(i, i + chunkSize);
    processChunk(chunk);
    
    // Yield to event loop
    await new Promise(resolve => setTimeout(resolve, 0));
  }
}

// ‚Üí Browser render opportunities m·ªói 50ms
// ‚Üí Input responsiveness maintained d∆∞·ªõi 100ms threshold
// ‚Üí T·ªïng th·ªùi gian: ~5100ms (2% overhead), nh∆∞ng UI v·∫´n interactive
```

**Performance Trade-off**: TƒÉng minimal total time (scheduling overhead) ƒë·ªïi l·∫°i perceived performance improvement dramatic

---

## 2. Microtask vs Macrotask - Ph√¢n Bi·ªát & ·ª®ng D·ª•ng

### 2.1. S·ª± Kh√°c Bi·ªát C·ªët L√µi

| Aspect | Microtask | Macrotask |
|--------|-----------|-----------|
| **Timing** | Ngay sau Call Stack r·ªóng | Sau khi T·∫§T C·∫¢ microtasks xong |
| **Quantity** | X·ª≠ l√Ω T·∫§T C·∫¢ trong queue | X·ª≠ l√Ω M·ªòT task m·ªói l·∫ßn |
| **Priority** | Cao h∆°n | Th·∫•p h∆°n |
| **Use Case** | State updates, Promise callbacks | User events, timers, I/O |
| **Render** | Tr∆∞·ªõc khi render | C√≥ th·ªÉ render gi·ªØa c√°c tasks |

### 2.2. Microtask Queue Sources

**Promise callbacks**:
```javascript
Promise.resolve()
  .then(() => {})    // Microtask
  .catch(() => {})   // Microtask
  .finally(() => {}); // Microtask
```

**queueMicrotask() API**:
```javascript
queueMicrotask(() => {
  console.log('Explicit microtask');
});
```

**MutationObserver** (Browser):
```javascript
const observer = new MutationObserver(() => {
  console.log('DOM mutation detected'); // Microtask
});
```

**process.nextTick()** (Node.js - highest priority):
```javascript
process.nextTick(() => {
  console.log('Next tick'); // Execute tr∆∞·ªõc Promise microtasks
});
```

### 2.3. Process.nextTick - Maximum Priority Microtask (Node.js)

**Ph√¢n bi·ªát quan tr·ªçng**: `process.nextTick()` execute tr∆∞·ªõc standard microtask queue, t·∫°o dedicated queue ri√™ng

**Th·ª© t·ª± ∆Øu ti√™n Execution** (Node.js):
```
1. process.nextTick() queue       ‚Üê Execute tr∆∞·ªõc ti√™n, ngay sau current operation
2. Promise microtask queue        ‚Üê .then/.catch/.finally callbacks
3. queueMicrotask()               ‚Üê Explicit microtask scheduling
4. Macrotask queues               ‚Üê setTimeout/setImmediate/I/O callbacks
```

**Use Cases ph√π h·ª£p**:
- **API Callback Guarantee**: ƒê·∫£m b·∫£o callbacks execute asynchronously ngay c·∫£ khi data s·∫µn c√≥ immediately
- **Event Emitter Pattern**: Cho ph√©p listeners ƒë∆∞·ª£c register tr∆∞·ªõc khi event emission
- **Recursive Operations**: Ph·∫£i complete tr∆∞·ªõc I/O events (v√≠ d·ª•: recursive directory traversal)

**C·∫£nh b√°o nghi√™m tr·ªçng**: Recursive `nextTick()` t·∫°o **microtask starvation** - blocks I/O v√¥ th·ªùi h·∫°n

```javascript
// ‚ùå NGUY HI·ªÇM: Starvation pattern
function recurse() {
  process.nextTick(recurse); // Infinite loop, I/O kh√¥ng bao gi·ªù execute
}

// ‚úÖ AN TO√ÄN: Cho ph√©p I/O gi·ªØa c√°c iterations
function recurse() {
  setImmediate(recurse); // Yields to I/O sau m·ªói iteration
}
```

### 2.4. QueueMicrotask API - Standard Microtask Scheduling

**M·ª•c ƒë√≠ch API**: Schedule microtask execution kh√¥ng c·∫ßn Promise wrapper overhead

**So s√°nh Performance**:
```javascript
// Promise-based: T·∫°o Promise object (allocation overhead)
Promise.resolve().then(callback); // ~10-20% ch·∫≠m h∆°n

// queueMicrotask: Direct queue insertion (minimal overhead)
queueMicrotask(callback);          // Nhanh h∆°n, kh√¥ng object allocation
```

**K·∫øt qu·∫£ Benchmark** (V8 engine):
- `Promise.resolve().then()`: ~0.05ms per invocation
- `queueMicrotask()`: ~0.04ms per invocation  
- **C·∫£i thi·ªán performance 20%** trong tight loops

**Khi n√†o n√™n d√πng**:
- **High-frequency scheduling**: Performance-critical paths v·ªõi frequent microtask creation
- **Non-Promise workflows**: Khi resolve/reject semantics kh√¥ng c·∫ßn thi·∫øt
- **Library internals**: Framework code c·∫ßn guaranteed microtask timing

**Khi n√†o n√™n tr√°nh**: Code h∆∞·ªüng l·ª£i t·ª´ Promise composability (chaining, error handling)

### 2.5. Macrotask Queue Sources

**setTimeout / setInterval**:
```javascript
setTimeout(() => {
  console.log('Macrotask');
}, 0);
```

**setImmediate** (Node.js):
```javascript
setImmediate(() => {
  console.log('Check phase macrotask');
});
```

**I/O callbacks**:
```javascript
fs.readFile('file.txt', (err, data) => {
  console.log('I/O macrotask');
});
```

**UI Events** (Browser):
```javascript
button.addEventListener('click', () => {
  console.log('Event macrotask');
});
```

### 2.6. Pitfall Nghi√™m Tr·ªçng: Microtask Starvation

**Nguy√™n nh√¢n g·ªëc**: Self-perpetuating microtask generation ngƒÉn ch·∫∑n event loop progression

**C∆° ch·∫ø Starvation**:
1. **Recursive Promise Chains**: M·ªói `.then()` schedule microtask kh√°c indefinitely
2. **MutationObserver Feedback Loop**: Observer callback triggers DOM mutation, re-queuing ch√≠nh n√≥
3. **Framework State Cascades**: setState triggering watchers m√† l·∫°i setState

**Tri·ªáu ch·ª©ng quan s√°t ƒë∆∞·ª£c**:
- **I/O Blockage**: Network requests, file operations, timers kh√¥ng bao gi·ªù execute
- **Rendering Freeze**: Browser kh√¥ng th·ªÉ paint frames (0 FPS)
- **Unresponsive UI**: Input events ƒë∆∞·ª£c queued nh∆∞ng kh√¥ng bao gi·ªù processed
- **DevTools Indication**: Long yellow scripting blocks trong Performance timeline

**V√≠ d·ª•: Promise Recursion Starvation**
```javascript
// ‚ùå T·∫°o infinite microtask loop
function starve() {
  Promise.resolve().then(() => {
    console.log('Microtask');
    starve(); // Immediately queues microtask kh√°c
  });
}
starve();
// K·∫øt qu·∫£: Logs flood console, UI ho√†n to√†n frozen

// ‚úÖ Cho ph√©p event loop progression
function safe() {
  setTimeout(() => {
    console.log('Macrotask');
    safe(); // Queues as macrotask, cho ph√©p rendering gi·ªØa iterations
  }, 0);
}
```

**Chi·∫øn l∆∞·ª£c Mitigation**:

1. **Depth Limiting**: Track recursion depth, switch sang macrotask sau threshold
```javascript
let depth = 0;
const MAX_DEPTH = 100;

function process() {
  if (depth++ < MAX_DEPTH) {
    queueMicrotask(process); // Fast path
  } else {
    depth = 0;
    setTimeout(process, 0); // Yield to event loop
  }
}
```

2. **Macrotask Yielding**: Explicitly break chains v·ªõi setTimeout(fn, 0)
3. **Monitoring**: Detect long microtask queues via Performance Observer

### 2.7. V√≠ D·ª• So S√°nh Chi Ti·∫øt

```javascript
console.log('1: Start');

// Macrotask
setTimeout(() => console.log('2: setTimeout'), 0);

// Microtask
Promise.resolve().then(() => console.log('3: Promise'));

// Microtask (Node.js - ∆∞u ti√™n cao nh·∫•t)
process.nextTick(() => console.log('4: nextTick'));

// Microtask
queueMicrotask(() => console.log('5: queueMicrotask'));

console.log('6: End');

// Output (Node.js):
// 1: Start
// 6: End
// 4: nextTick          ‚Üê Cao nh·∫•t trong Microtask
// 3: Promise           ‚Üê Microtask
// 5: queueMicrotask    ‚Üê Microtask
// 2: setTimeout        ‚Üê Macrotask
```

**Ph√¢n t√≠ch chi ti·∫øt**:

| B∆∞·ªõc | Call Stack | Microtask Queue | Macrotask Queue | Console Output |
|------|-----------|-----------------|-----------------|----------------|
| 1 | `console.log('1: Start')` | [] | [] | "1: Start" |
| 2 | - | [] | [`setTimeout`] | - |
| 3 | - | [`Promise handler`] | [`setTimeout`] | - |
| 4 | - | [`nextTick`, `Promise handler`] | [`setTimeout`] | - |
| 5 | - | [`nextTick`, `Promise`, `queueMicrotask`] | [`setTimeout`] | - |
| 6 | `console.log('6: End')` | [`nextTick`, `Promise`, `queueMicrotask`] | [`setTimeout`] | "6: End" |
| 7 | `nextTick handler` | [`Promise`, `queueMicrotask`] | [`setTimeout`] | "4: nextTick" |
| 8 | `Promise handler` | [`queueMicrotask`] | [`setTimeout`] | "3: Promise" |
| 9 | `queueMicrotask handler` | [] | [`setTimeout`] | "5: queueMicrotask" |
| 10 | `setTimeout handler` | [] | [] | "2: setTimeout" |

### 2.8. Real-World Use Cases

#### Use Case 1: React Concurrent Mode

React s·ª≠ d·ª•ng **scheduler** ƒë·ªÉ:
- High priority updates ‚Üí Microtasks (user input)
- Low priority updates ‚Üí Macrotasks (background updates)
- Cho ph√©p interrupt long tasks ƒë·ªÉ render urgent updates

```javascript
// React internally uses scheduler
// High priority: User input
scheduleCallback(ImmediatePriority, handleInput);

// Low priority: Background data fetch
scheduleCallback(IdlePriority, fetchData);
```

#### Use Case 2: Database Transaction Batching

**V·∫•n ƒë·ªÅ**: Multiple DB updates ‚Üí multiple round-trips

**Gi·∫£i ph√°p**: Batch v·ªõi microtasks
```javascript
const pendingUpdates = [];

function update(data) {
  pendingUpdates.push(data);
  
  // Schedule batch processing if not already scheduled
  if (pendingUpdates.length === 1) {
    queueMicrotask(() => {
      const batch = [...pendingUpdates];
      pendingUpdates.length = 0;
      
      db.batchUpdate(batch); // Single query
    });
  }
}

// Usage:
update({ id: 1, value: 'a' });
update({ id: 2, value: 'b' });
update({ id: 3, value: 'c' });
// ‚Üí Send batch request khi t·∫•t c·∫£ microtasks done
```

#### Use Case 3: Animation Frame Scheduling

**RequestAnimationFrame**: Macrotask ƒë·∫∑c bi·ªát
- Ch·∫°y **tr∆∞·ªõc** rendering
- ~60 FPS (16.67ms/frame)

**Pattern**:
```
Microtasks ‚Üí requestAnimationFrame ‚Üí Render ‚Üí Macrotasks
```

```javascript
let frame = 0;

function animate() {
  // Update state (microtask may be queued here)
  Promise.resolve().then(() => {
    console.log('State update in microtask');
  });
  
  // Visual update
  element.style.transform = `translateX(${frame}px)`;
  frame++;
  
  // Schedule next frame (macrotask)
  requestAnimationFrame(animate);
}

requestAnimationFrame(animate);
```

---

## 3. Promises - Internals & Production Patterns

### 3.1. Promise State Machine Internals

**M√¥ h√¨nh State Transition**: Unidirectional state machine v·ªõi 3 states kh·∫£ dƒ©

```
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇ PENDING ‚îÇ  State ban ƒë·∫ßu
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ                         ‚îÇ
     resolve(value)            reject(reason)
           ‚îÇ                         ‚îÇ
           ‚ñº                         ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ FULFILLED‚îÇ              ‚îÇ REJECTED ‚îÇ  Terminal states
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**ƒê·∫∑c ƒëi·ªÉm c·ªßa t·ª´ng State**:
- **Pending**: State ban ƒë·∫ßu; promise ch∆∞a fulfilled ho·∫∑c rejected
  - Internal `[[PromiseState]]`: "pending"
  - Ch∆∞a c√≥ `[[PromiseResult]]` value
  - ƒêang ch·ªù resolution th√¥ng qua executor function

- **Fulfilled**: Operation ho√†n th√†nh th√†nh c√¥ng
  - State transition l√† **kh√¥ng th·ªÉ ƒë·∫£o ng∆∞·ª£c** (irreversible)
  - `[[PromiseResult]]` ch·ª©a resolution value
  - T·∫•t c·∫£ registered `.then(onFulfilled)` handlers enqueued as microtasks

- **Rejected**: Operation failed v·ªõi error
  - State transition l√† **kh√¥ng th·ªÉ ƒë·∫£o ng∆∞·ª£c** (irreversible)
  - `[[PromiseResult]]` ch·ª©a rejection reason
  - T·∫•t c·∫£ registered `.catch(onRejected)` handlers enqueued as microtasks

**Thu·ªôc t√≠nh Critical**:
1. **Immutability**: Sau khi settled (fulfilled/rejected), state v√† value kh√¥ng th·ªÉ thay ƒë·ªïi
2. **Handler Registration**: Callbacks attach sau settlement execute immediately (as microtasks)
3. **Chain Creation**: M·ªói `.then()/.catch()/.finally()` return **Promise m·ªõi**, enabling composition

### 3.2. Promise Internal Structure (Simplified)

```javascript
// Simplified internal structure
class MyPromise {
  constructor(executor) {
    this.state = 'pending';
    this.value = undefined;
    this.reason = undefined;
    this.onFulfilledCallbacks = [];
    this.onRejectedCallbacks = [];
    
    const resolve = (value) => {
      if (this.state === 'pending') {
        this.state = 'fulfilled';
        this.value = value;
        this.onFulfilledCallbacks.forEach(fn => fn(value));
      }
    };
    
    const reject = (reason) => {
      if (this.state === 'pending') {
        this.state = 'rejected';
        this.reason = reason;
        this.onRejectedCallbacks.forEach(fn => fn(reason));
      }
    };
    
    try {
      executor(resolve, reject);
    } catch (error) {
      reject(error);
    }
  }
  
  then(onFulfilled, onRejected) {
    return new MyPromise((resolve, reject) => {
      if (this.state === 'fulfilled') {
        queueMicrotask(() => {
          try {
            const result = onFulfilled(this.value);
            resolve(result);
          } catch (error) {
            reject(error);
          }
        });
      }
      
      if (this.state === 'rejected') {
        queueMicrotask(() => {
          try {
            const result = onRejected(this.reason);
            resolve(result);
          } catch (error) {
            reject(error);
          }
        });
      }
      
      if (this.state === 'pending') {
        this.onFulfilledCallbacks.push((value) => {
          queueMicrotask(() => {
            try {
              const result = onFulfilled(value);
              resolve(result);
            } catch (error) {
              reject(error);
            }
          });
        });
        
        this.onRejectedCallbacks.push((reason) => {
          queueMicrotask(() => {
            try {
              const result = onRejected(reason);
              resolve(result);
            } catch (error) {
              reject(error);
            }
          });
        });
      }
    });
  }
  
  catch(onRejected) {
    return this.then(null, onRejected);
  }
  
  finally(onFinally) {
    return this.then(
      value => {
        onFinally();
        return value;
      },
      reason => {
        onFinally();
        throw reason;
      }
    );
  }
}
```

### 3.3. Promise Chaining - Anti-Patterns v√† Best Practices

**Anti-Pattern 1: Nested Promises ("Callback Hell 2.0")**
```javascript
// ‚ùå Promise nesting - defeats the purpose
getUserData()
  .then(user => {
    return getUserPosts(user.id)
      .then(posts => {
        return getPostComments(posts[0].id)
          .then(comments => {
            // Deeply nested, hard to read
            return { user, posts, comments };
          });
      });
  });
```

**Best Practice: Flat Promise Chain**
```javascript
// ‚úÖ Flat chain - readable and composable
let userData, postsData;

getUserData()
  .then(user => {
    userData = user;
    return getUserPosts(user.id);
  })
  .then(posts => {
    postsData = posts;
    return getPostComments(posts[0].id);
  })
  .then(comments => ({ 
    user: userData, 
    posts: postsData, 
    comments 
  }))
  .catch(error => {
    // Centralized error handling for entire chain
    console.error('Pipeline failed:', error);
  });
```

**L·ª£i th·∫ø ch√≠nh**:
- **Flat structure**: Lo·∫°i b·ªè rightward drift, c·∫£i thi·ªán readability
- **Error propagation**: Single `.catch()` x·ª≠ l√Ω errors t·ª´ b·∫•t k·ª≥ step n√†o
- **Type inference**: M·ªói `.then()` cung c·∫•p clear input/output contract

### 3.4. Promise Static Methods - Strategic Selection Guide

#### Promise.all() - Parallel Execution v·ªõi Fail-Fast Semantics

**Use Cases t·ªëi ∆∞u**:
- **Independent resource fetching**: Load user data, settings, v√† permissions ƒë·ªìng th·ªùi
- **Parallel computation**: X·ª≠ l√Ω multiple data chunks simultaneously
- **Atomic operations**: All-or-nothing batch updates (database transactions)

**ƒê·∫∑c ƒëi·ªÉm Execution**:
```javascript
const results = await Promise.all([
  fetchUser(),        // 100ms
  fetchSettings(),    // 150ms  
  fetchPermissions()  // 120ms
]);
// T·ªïng th·ªùi gian: max(100, 150, 120) = 150ms (kh√¥ng ph·∫£i 370ms sequential)
// Returns: [userData, settingsData, permissionsData]
```

**Gi·ªõi h·∫°n quan tr·ªçng**:
- **Fail-fast behavior**: Rejection ƒë·∫ßu ti√™n immediately rejects to√†n b·ªô Promise.all()
  ```javascript
  Promise.all([
    Promise.resolve(1),
    Promise.reject(new Error('fail')), // Rejection ·ªü ƒë√¢y
    Promise.resolve(3),
  ]); // Immediately rejects, results [1, 3] b·ªã m·∫•t
  ```
- **No partial results**: Successful promises' values kh√¥ng accessible khi rejection
- **Resource waste**: C√°c requests kh√°c v·∫´n ti·∫øp t·ª•c execute nh∆∞ng results b·ªã discard

**Khi n√†o n√™n tr√°nh**: Operations m√† partial success l√† acceptable (d√πng `Promise.allSettled()`)

**Implementation (Simplified)**:
```javascript
Promise.myAll = function(promises) {
  return new Promise((resolve, reject) => {
    const results = [];
    let completedCount = 0;
    
    if (promises.length === 0) {
      resolve(results);
      return;
    }
    
    promises.forEach((promise, index) => {
      Promise.resolve(promise)
        .then(value => {
          results[index] = value;
          completedCount++;
          
          if (completedCount === promises.length) {
            resolve(results);
          }
        })
        .catch(reject); // Reject ngay khi c√≥ 1 promise fail
    });
  });
};
```

#### Promise.race() - First Completion Wins

**Use Cases**:

**1. Timeout Pattern**:
```javascript
function fetchWithTimeout(url, timeout = 5000) {
  return Promise.race([
    fetch(url),
    new Promise((_, reject) => 
      setTimeout(() => reject(new Error('Request timeout')), timeout)
    )
  ]);
}
```

**2. Fastest Server (Redundant Requests)**:
```javascript
// Race gi·ªØa multiple servers, d√πng response nhanh nh·∫•t
const data = await Promise.race([
  fetch('https://api1.example.com/data'),
  fetch('https://api2.example.com/data'),
  fetch('https://api3.example.com/data')
]);
// ‚Üí TƒÉng reliability v√† gi·∫£m latency
```

**3. User Action vs Auto-save**:
```javascript
// Race gi·ªØa user click save vs auto-save timeout
await Promise.race([
  userClickSave(),      // User triggers save
  autoSaveTimeout(30000) // Auto-save after 30s
]);
```

**Implementation (Simplified)**:
```javascript
Promise.myRace = function(promises) {
  return new Promise((resolve, reject) => {
    promises.forEach(promise => {
      Promise.resolve(promise)
        .then(resolve)  // Resolve ngay khi c√≥ promise ƒë·∫ßu ti√™n ho√†n th√†nh
        .catch(reject); // Reject ngay khi c√≥ promise ƒë·∫ßu ti√™n fail
    });
  });
};
```

#### Promise.allSettled() - Fault-Tolerant Aggregation Pattern

**Tri·∫øt l√Ω thi·∫øt k·∫ø**: Ch·ªù t·∫•t c·∫£ promises b·∫•t k·ªÉ outcome, kh√¥ng bao gi·ªù reject

**C·∫•u tr√∫c Return Value**:
```javascript
const results = await Promise.allSettled([
  Promise.resolve(42),
  Promise.reject(new Error('failed')),
  Promise.resolve('success'),
]);

// results structure:
[
  { status: 'fulfilled', value: 42 },
  { status: 'rejected', reason: Error('failed') },
  { status: 'fulfilled', value: 'success' }
]
```

**Production Use Case: Microservices Aggregation**
```javascript
// Scenario: Dashboard fetching t·ª´ 5 microservices
const serviceResults = await Promise.allSettled([
  fetchUserService(),       // Success: 200ms
  fetchAnalyticsService(),  // Timeout: 5000ms
  fetchNotificationService(), // Success: 150ms
  fetchPaymentService(),    // Error 500: 300ms
  fetchInventoryService(),  // Success: 180ms
]);

// Graceful degradation strategy
const successfulData = Object.fromEntries(
  serviceResults
    .map((result, idx) => [
      serviceNames[idx],
      result.status === 'fulfilled' ? result.value : null
    ])
    .filter(([_, value]) => value !== null)
);

// Dashboard hi·ªÉn th·ªã: User data (‚úì), Notifications (‚úì), Inventory (‚úì)
// Gracefully handles: Analytics timeout, Payment service error
// User th·∫•y: Partial UI v·ªõi error indicators cho failed services
```

**L·ª£i √≠ch**:
- **Partial degradation**: Application v·∫´n functional d√π c√≥ partial failures
- **Complete observability**: Bi·∫øt ch√≠nh x√°c operations n√†o succeeded/failed
- **Better UX**: Hi·ªÉn th·ªã available data thay v√¨ blank error screen

**Implementation (Simplified)**:
```javascript
Promise.myAllSettled = function(promises) {
  return new Promise(resolve => {
    const results = [];
    let completedCount = 0;
    
    if (promises.length === 0) {
      resolve(results);
      return;
    }
    
    promises.forEach((promise, index) => {
      Promise.resolve(promise)
        .then(value => {
          results[index] = { status: 'fulfilled', value };
        })
        .catch(reason => {
          results[index] = { status: 'rejected', reason };
        })
        .finally(() => {
          completedCount++;
          if (completedCount === promises.length) {
            resolve(results);
          }
        });
    });
  });
};
```

#### Promise.any() - First Success Wins

**Use case**: Ch·ªù promise ƒë·∫ßu ti√™n succeed, ignore rejections cho ƒë·∫øn khi t·∫•t c·∫£ fail

```javascript
// Example: Try multiple CDNs
const script = await Promise.any([
  loadScript('https://cdn1.example.com/lib.js'),
  loadScript('https://cdn2.example.com/lib.js'),
  loadScript('https://cdn3.example.com/lib.js')
]);
// ‚Üí Load t·ª´ CDN nhanh nh·∫•t available
```

**Khi n√†o d√πng**:
- Fallback mechanisms v·ªõi multiple sources
- Load balancing across redundant servers
- First successful response sufficient

### 3.5. Unhandled Promise Rejections

**V·∫•n ƒë·ªÅ nghi√™m tr·ªçng**: Promise rejections kh√¥ng ƒë∆∞·ª£c catch d·∫´n ƒë·∫øn silent failures

**Node.js Global Handler**:
```javascript
process.on('unhandledRejection', (reason, promise) => {
  console.error('Unhandled Rejection at:', promise, 'reason:', reason);
  
  // Log to monitoring service (Sentry, Datadog, etc.)
  logger.error('Unhandled Promise Rejection', {
    reason,
    stack: reason?.stack,
    timestamp: Date.now()
  });
  
  // Graceful shutdown n·∫øu critical
  if (isCriticalError(reason)) {
    process.exit(1);
  }
});
```

**Browser Global Handler**:
```javascript
window.addEventListener('unhandledrejection', (event) => {
  console.error('Unhandled Promise Rejection:', event.reason);
  
  // Prevent default browser error handling
  event.preventDefault();
  
  // Log to error tracking service
  if (window.Sentry) {
    Sentry.captureException(event.reason);
  }
  
  // Hi·ªÉn th·ªã error UI cho user
  showErrorToast({
    message: 'Something went wrong. Please try again.',
    technical: event.reason.message
  });
});
```

**Best Practices**:
- **Lu√¥n lu√¥n** d√πng `.catch()` ho·∫∑c `try-catch` v·ªõi async/await
- Global handlers l√†m safety net, kh√¥ng ph·∫£i primary error handling
- Monitor unhandled rejections trong production v√† set up alerts
- Log ƒë·∫ßy ƒë·ªß context (stack trace, user state, request details)

---

## 4. Async/Await - Advanced Techniques

### 4.1. Async/Await L√† G√¨ Th·ª±c S·ª±?

**B·∫£n ch·∫•t**: Syntactic sugar tr√™n Promises + Generators

**C∆° ch·∫ø Internally**:
```javascript
async function fetchData() {  // ‚Üí Returns Promise
  const result = await apiCall(); // ‚Üí Pause execution, yield to Event Loop
  return result;  // ‚Üí Code sau await ƒë∆∞·ª£c wrapped trong .then()
}
```

**Compiler transformation (conceptual)**:
```javascript
// Code b·∫°n vi·∫øt
async function example() {
  const a = await fetch('/api/a');
  const b = await fetch('/api/b');
  return { a, b };
}

// T∆∞∆°ng ƒë∆∞∆°ng v·ªõi
function example() {
  return fetch('/api/a')
    .then(a => fetch('/api/b')
    .then(b => ({ a, b })));
}
```

**L·ª£i th·∫ø ch√≠nh**:
- **Synchronous-looking code**: D·ªÖ ƒë·ªçc v√† hi·ªÉu h∆°n Promise chains
- **Better error handling**: D√πng try-catch quen thu·ªôc thay v√¨ .catch()
- **Easier debugging**: Call stack ƒë∆∞·ª£c preserved, d·ªÖ debug h∆°n

### 4.2. Sequential vs Parallel Execution - Performance Critical

**Anti-pattern ph·ªï bi·∫øn**: Unintentional sequential execution

```javascript
// ‚ùå Await trong loop ‚Üí x·ª≠ l√Ω tu·∫ßn t·ª± (ch·∫≠m)
async function fetchAllUsers(userIds) {
  const users = [];
  for (const id of userIds) {
    const user = await fetchUser(id);  // Ch·ªù m·ªói request xong m·ªõi ti·∫øp t·ª•c
    users.push(user);
  }
  return users;
}
// T·ªïng th·ªùi gian: 10 users √ó 100ms = 1000ms
```

**Best practice**: Parallel execution khi possible

```javascript
// ‚úÖ Promise.all ‚Üí x·ª≠ l√Ω song song (nhanh)
async function fetchAllUsers(userIds) {
  const promises = userIds.map(id => fetchUser(id));
  return await Promise.all(promises);
}
// T·ªïng th·ªùi gian: max(100ms) = 100ms (parallel)
// Performance improvement: 10x faster!
```

**When to use sequential** (ngo·∫°i l·ªá):
- Requests ph·ª• thu·ªôc nhau (result c·ªßa request 1 c·∫ßn cho request 2)
- Rate limiting considerations
- Resource constraints (memory, connections)
- Waterfall dependencies

```javascript
// Sequential l√† c·∫ßn thi·∫øt khi c√≥ dependency
async function processUserData() {
  const user = await fetchUser();
  const posts = await fetchUserPosts(user.id); // C·∫ßn user.id
  const comments = await fetchPostComments(posts[0].id); // C·∫ßn posts
  return { user, posts, comments };
}
```

### 4.3. Error Handling Patterns - Chi·∫øn L∆∞·ª£c T·ªëi ∆Øu

#### Pattern 1: Try-Catch per Operation (Granular)

```javascript
async function processData() {
  let userData, settingsData;
  
  try {
    userData = await fetchUser();
  } catch (error) {
    console.error('User fetch failed:', error);
    userData = getDefaultUser(); // Fallback
  }
  
  try {
    settingsData = await fetchSettings();
  } catch (error) {
    console.error('Settings fetch failed:', error);
    settingsData = getDefaultSettings(); // Fallback
  }
  
  return { userData, settingsData };
}
```

**Pros**: Granular error handling, specific fallbacks
**Cons**: Verbose, nhi·ªÅu boilerplate code

#### Pattern 2: Single Try-Catch for Entire Function (Concise)

```javascript
async function processData() {
  try {
    const userData = await fetchUser();
    const settingsData = await fetchSettings();
    return { userData, settingsData };
  } catch (error) {
    console.error('Process failed:', error);
    return getDefaultData();
  }
}
```

**Pros**: Concise, d·ªÖ ƒë·ªçc
**Cons**: Kh√¥ng differentiate ƒë∆∞·ª£c errors, t·∫•t c·∫£ l·ªói ƒë·ªÅu x·ª≠ l√Ω gi·ªëng nhau

#### Pattern 3: Error-First Approach (Go-style)

```javascript
async function fetchData() {
  const [error, data] = await fetchUser()
    .then(data => [null, data])
    .catch(error => [error, null]);
  
  if (error) {
    // Explicit error handling
    return handleError(error);
  }
  
  return processData(data);
}
```

**Pros**: Explicit, forces error handling
**Cons**: Nhi·ªÅu boilerplate

**Recommendation**: D√πng Pattern 2 cho most cases, Pattern 1 khi c·∫ßn specific error handling

### 4.4. Advanced Async Patterns

#### Pattern: Retry with Exponential Backoff

```javascript
async function fetchWithRetry(url, options = {}) {
  const {
    maxRetries = 3,
    retryDelay = 1000,
    backoff = 'exponential' // 'exponential' | 'linear'
  } = options;
  
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await fetch(url);
    } catch (error) {
      const isLastAttempt = i === maxRetries - 1;
      
      if (isLastAttempt) {
        throw error;
      }
      
      const delay = backoff === 'exponential'
        ? retryDelay * Math.pow(2, i)
        : retryDelay * (i + 1);
      
      console.log(`Retry ${i + 1}/${maxRetries} after ${delay}ms`);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
}

// Usage
const data = await fetchWithRetry('/api/data', {
  maxRetries: 3,
  retryDelay: 1000,
  backoff: 'exponential'
});
```

#### Pattern: Timeout Wrapper

```javascript
function withTimeout(promise, timeoutMs) {
  return Promise.race([
    promise,
    new Promise((_, reject) => {
      setTimeout(() => {
        reject(new Error(`Timeout after ${timeoutMs}ms`));
      }, timeoutMs);
    })
  ]);
}

// Usage
try {
  const data = await withTimeout(
    fetch('/api/slow-endpoint'),
    5000 // 5s timeout
  );
} catch (error) {
  console.error('Request timeout or failed:', error);
}
```

#### Pattern: Promise Pool (Concurrency Limit)

```javascript
async function promisePool(tasks, concurrency) {
  const results = [];
  const executing = [];
  
  for (const task of tasks) {
    const promise = Promise.resolve().then(() => task());
    results.push(promise);
    
    if (concurrency <= tasks.length) {
      const executingPromise = promise.then(() => {
        executing.splice(executing.indexOf(executingPromise), 1);
      });
      
      executing.push(executingPromise);
      
      if (executing.length >= concurrency) {
        await Promise.race(executing);
      }
    }
  }
  
  return Promise.all(results);
}

// Usage: Fetch 100 URLs with max 5 concurrent requests
const urls = Array.from({ length: 100 }, (_, i) => `/api/item/${i}`);
const tasks = urls.map(url => () => fetch(url));

const results = await promisePool(tasks, 5);
```

---

## 5. Advanced Async Patterns

### 5.1. AbortController - Request Cancellation

**Problem**: Kh√¥ng th·ªÉ cancel in-flight async operations

**Solution**: AbortController API (modern browsers & Node.js 15+)

**Basic Usage**:
```javascript
const controller = new AbortController();
const signal = controller.signal;

// Start fetch with abort signal
fetch('/api/data', { signal })
  .then(response => response.json())
  .then(data => console.log(data))
  .catch(error => {
    if (error.name === 'AbortError') {
      console.log('Request cancelled');
    } else {
      console.error('Request failed:', error);
    }
  });

// Cancel request after 5s
setTimeout(() => controller.abort(), 5000);
```

**Use Case: Search Autocomplete**:
```javascript
let currentController = null;

async function searchAPI(query) {
  // Cancel previous request
  if (currentController) {
    currentController.abort();
  }
  
  // Create new controller
  currentController = new AbortController();
  
  try {
    const response = await fetch(`/api/search?q=${query}`, {
      signal: currentController.signal
    });
    return await response.json();
  } catch (error) {
    if (error.name === 'AbortError') {
      console.log('Search cancelled');
      return null;
    }
    throw error;
  }
}

// User types rapidly
searchAPI('h');   // Starts request
searchAPI('he');  // Cancels previous, starts new
searchAPI('hel'); // Cancels previous, starts new
// Only last request completes
```

**Khi n√†o d√πng**:
- User-initiated requests (search, autocomplete)
- Navigating gi·ªØa pages
- Timeout implementations
- Component cleanup (React useEffect)

### 5.2. Debounce & Throttle - Rate Limiting

#### Debounce: Ch·ªù user ng·ª´ng input

```javascript
function debounce(func, delay) {
  let timeoutId;
  
  return function(...args) {
    clearTimeout(timeoutId);
    
    timeoutId = setTimeout(() => {
      func.apply(this, args);
    }, delay);
  };
}

// Use case: Search autocomplete
const searchDebounced = debounce(async (query) => {
  const results = await fetch(`/api/search?q=${query}`);
  displayResults(results);
}, 300);

// User types "hello"
// h -> start timer (300ms)
// he -> reset timer
// hel -> reset timer  
// hell -> reset timer
// hello -> reset timer
// (300ms l√† kh√¥ng g√µ g√¨) -> API call!

searchInput.addEventListener('input', (e) => {
  searchDebounced(e.target.value);
});
```

#### Throttle: Gi·ªõi h·∫°n t·∫ßn su·∫•t

```javascript
function throttle(func, limit) {
  let inThrottle;
  
  return function(...args) {
    if (!inThrottle) {
      func.apply(this, args);
      inThrottle = true;
      
      setTimeout(() => {
        inThrottle = false;
      }, limit);
    }
  };
}

// Use case: Scroll events
const handleScrollThrottled = throttle(() => {
  console.log('Scroll position:', window.scrollY);
  // Update UI based on scroll
}, 100);

window.addEventListener('scroll', handleScrollThrottled);
// Execute t·ªëi ƒëa 1 l·∫ßn/100ms
// Events gi·ªØa c√°c l·∫ßn execute b·ªã discard
```

**Khi n√†o d√πng**:
- **Debounce**: Search, form validation, window resize
- **Throttle**: Scroll events, mousemove, game loop updates

### 5.3. Race Conditions - Patterns & Solutions

#### Type 1: Request Race

**Problem**: Later request starts first, earlier finishes last ‚Üí stale data

**Solution 1: Request ID Tracking**:
```javascript
let latestRequestId = 0;

async function loadUser(userId) {
  const requestId = ++latestRequestId;
  
  const response = await fetch(`/api/users/${userId}`);
  const data = await response.json();
  
  // Ch·ªâ update n·∫øu ƒë√¢y l√† request m·ªõi nh·∫•t
  if (requestId === latestRequestId) {
    userData = data;
  }
}
```

**Solution 2: AbortController** (Preferred):
```javascript
let currentController = null;

async function loadUser(userId) {
  if (currentController) {
    currentController.abort();
  }
  
  currentController = new AbortController();
  
  const response = await fetch(`/api/users/${userId}`, {
    signal: currentController.signal
  });
  userData = await response.json();
}
```

#### Type 2: State Race

**Problem**: Multiple async updates to same state

```javascript
// ‚ùå BAD: Race condition
let count = 0;

async function increment() {
  const current = count;
  await delay(100);
  count = current + 1;
}

increment(); // count = 0 ‚Üí 1
increment(); // count = 0 ‚Üí 1 (WRONG! Should be 2)
```

**Solution: Atomic updates** (React functional updates):
```javascript
const [count, setCount] = useState(0);

function increment() {
  setCount(prev => prev + 1); // Always correct, based on latest state
}
```

#### Type 3: Database Race

**Problem**: Read-modify-write race condition

```javascript
// ‚ùå BAD: Non-atomic update
async function incrementLikes(postId) {
  const post = await db.posts.findOne({ id: postId });
  post.likes += 1;
  await db.posts.update({ id: postId }, post);
}
// Two concurrent calls can both read likes=10, both set to 11

// ‚úÖ GOOD: Atomic update
async function incrementLikes(postId) {
  await db.posts.update(
    { id: postId },
    { $inc: { likes: 1 } } // Atomic increment
  );
}
```

### 5.4. Mutex Lock Pattern

**Use case**: Ensure sequential execution of critical sections

```javascript
class Mutex {
  constructor() {
    this.locked = false;
    this.queue = [];
  }
  
  async lock() {
    if (!this.locked) {
      this.locked = true;
      return;
    }
    
    return new Promise(resolve => {
      this.queue.push(resolve);
    });
  }
  
  unlock() {
    if (this.queue.length > 0) {
      const resolve = this.queue.shift();
      resolve();
    } else {
      this.locked = false;
    }
  }
}

// Usage
const mutex = new Mutex();

async function criticalSection() {
  await mutex.lock();
  
  try {
    // Critical code - only one execution at a time
    const data = await readData();
    await processData(data);
    await writeData(data);
  } finally {
    mutex.unlock();
  }
}
```

### 5.5. Circuit Breaker Pattern

**Purpose**: Prevent cascading failures, fast-fail when service is down

```javascript
class CircuitBreaker {
  constructor(fn, options = {}) {
    this.fn = fn;
    this.failureThreshold = options.failureThreshold || 5;
    this.resetTimeout = options.resetTimeout || 60000;
    this.state = 'CLOSED'; // CLOSED, OPEN, HALF_OPEN
    this.failureCount = 0;
    this.nextAttempt = Date.now();
  }
  
  async execute(...args) {
    if (this.state === 'OPEN') {
      if (Date.now() < this.nextAttempt) {
        throw new Error('Circuit breaker is OPEN');
      }
      
      this.state = 'HALF_OPEN';
    }
    
    try {
      const result = await this.fn(...args);
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }
  
  onSuccess() {
    this.failureCount = 0;
    this.state = 'CLOSED';
  }
  
  onFailure() {
    this.failureCount++;
    
    if (this.failureCount >= this.failureThreshold) {
      this.state = 'OPEN';
      this.nextAttempt = Date.now() + this.resetTimeout;
    }
  }
}

// Usage
const fetchWithCircuitBreaker = new CircuitBreaker(
  async (url) => {
    const response = await fetch(url);
    if (!response.ok) throw new Error('Fetch failed');
    return response.json();
  },
  {
    failureThreshold: 3,
    resetTimeout: 30000
  }
);

try {
  const data = await fetchWithCircuitBreaker.execute('/api/data');
} catch (error) {
  console.error('Circuit breaker prevented request:', error);
}
```

---

## 6. Async Iteration & Generators

### 6.1. Async Iterators - for await...of

**Concept**: Iterate over async data sources sequentially

**Async Iterable Protocol**:
```javascript
// Object ph·∫£i implement Symbol.asyncIterator
const asyncIterable = {
  async *[Symbol.asyncIterator]() {
    yield 1;
    yield 2;
    yield 3;
  }
};

// Usage
for await (const value of asyncIterable) {
  console.log(value); // 1, 2, 3
}
```

**Use Case: Paginated API**:
```javascript
async function* fetchAllPages(url) {
  let page = 1;
  let hasMore = true;
  
  while (hasMore) {
    const response = await fetch(`${url}?page=${page}`);
    const data = await response.json();
    
    yield data.items;  // Yield m·ªói page
    
    hasMore = data.hasMore;
    page++;
  }
}

// Usage
for await (const items of fetchAllPages('/api/users')) {
  console.log('Processing page:', items.length, 'items');
  processItems(items);
}
```

**L·ª£i √≠ch**:
- **Memory efficient**: Kh√¥ng load t·∫•t c·∫£ data v√†o memory c√πng l√∫c
- **Lazy evaluation**: Ch·ªâ fetch khi c·∫ßn
- **Clean syntax**: For-await-of loop d·ªÖ ƒë·ªçc
- **Back-pressure support**: C√≥ th·ªÉ pause/resume iteration

### 6.2. Async Generators - async function*

**Syntax**: Combine async functions v·ªõi generators

```javascript
async function* generateSequence() {
  for (let i = 1; i <= 3; i++) {
    await delay(1000); // Simulate async operation
    yield i;
  }
}

// Usage
const generator = generateSequence();

console.log(await generator.next()); // { value: 1, done: false } after 1s
console.log(await generator.next()); // { value: 2, done: false } after 2s
console.log(await generator.next()); // { value: 3, done: false } after 3s
console.log(await generator.next()); // { value: undefined, done: true }
```

**Use Case: Stream Processing**:
```javascript
async function* processLogFile(filePath) {
  const fileHandle = await fs.open(filePath, 'r');
  const stream = fileHandle.createReadStream();
  
  let buffer = '';
  
  for await (const chunk of stream) {
    buffer += chunk;
    const lines = buffer.split('\n');
    buffer = lines.pop(); // Keep incomplete line in buffer
    
    for (const line of lines) {
      const parsed = parseLogLine(line);
      if (parsed) {
        yield parsed;
      }
    }
  }
  
  // Process remaining buffer
  if (buffer.trim()) {
    const parsed = parseLogLine(buffer);
    if (parsed) yield parsed;
  }
  
  await fileHandle.close();
}

// Usage: Process large log file without loading all into memory
for await (const logEntry of processLogFile('/var/log/app.log')) {
  if (logEntry.level === 'ERROR') {
    console.error('Error found:', logEntry);
  }
}
```

**Use Case: Infinite Sequences**:
```javascript
async function* infiniteStream() {
  let id = 0;
  
  while (true) {
    // Fetch real-time data
    const data = await fetch('/api/stream');
    const json = await data.json();
    
    yield { id: id++, ...json };
    
    // Polling interval
    await delay(5000);
  }
}

// Usage with break condition
for await (const item of infiniteStream()) {
  processItem(item);
  
  if (shouldStop()) {
    break; // Exit infinite loop
  }
}
```

**Real-World Examples**:

**1. CSV Streaming**:
```javascript
async function* parseCSV(filePath) {
  const fileHandle = await fs.open(filePath);
  const stream = fileHandle.createReadStream();
  
  let buffer = '';
  let isFirstLine = true;
  let headers = [];
  
  for await (const chunk of stream) {
    buffer += chunk;
    const lines = buffer.split('\n');
    buffer = lines.pop();
    
    for (const line of lines) {
      if (isFirstLine) {
        headers = line.split(',');
        isFirstLine = false;
        continue;
      }
      
      const values = line.split(',');
      const row = Object.fromEntries(
        headers.map((h, i) => [h, values[i]])
      );
      
      yield row;
    }
  }
}

// Process 1GB CSV file
for await (const row of parseCSV('large-data.csv')) {
  await processRow(row); // Process one row at a time
}
```

**2. Database Cursor Streaming**:
```javascript
async function* queryStream(query) {
  const cursor = db.collection('users').find(query);
  
  while (await cursor.hasNext()) {
    yield await cursor.next();
  }
  
  await cursor.close();
}

// Process millions of records
for await (const user of queryStream({ active: true })) {
  await sendEmail(user);
}
```

### 6.3. Combining Async Iterators

**Pattern: Transform Stream**:
```javascript
async function* map(asyncIterable, transformFn) {
  for await (const item of asyncIterable) {
    yield await transformFn(item);
  }
}

async function* filter(asyncIterable, predicateFn) {
  for await (const item of asyncIterable) {
    if (await predicateFn(item)) {
      yield item;
    }
  }
}

// Usage: Pipeline
const numbers = fetchNumbers(); // async generator
const doubled = map(numbers, x => x * 2);
const evens = filter(doubled, x => x % 2 === 0);

for await (const num of evens) {
  console.log(num);
}
```

---

## 7. Error Handling in Production

### 7.1. Unhandled Promise Rejections

**Node.js Global Handler**:
```javascript
process.on('unhandledRejection', (reason, promise) => {
  console.error('Unhandled Rejection at:', promise);
  console.error('Reason:', reason);
  
  // Log to monitoring service
  logger.error('Unhandled Promise Rejection', {
    reason,
    stack: reason?.stack,
    timestamp: new Date().toISOString(),
    environment: process.env.NODE_ENV
  });
  
  // Alert on-call engineer for critical errors
  if (isCriticalError(reason)) {
    alertOncall({
      severity: 'critical',
      message: 'Unhandled Promise Rejection',
      details: reason
    });
  }
});

// Graceful shutdown on critical errors
process.on('unhandledRejection', (reason) => {
  if (isCriticalError(reason)) {
    console.error('Critical error, shutting down...');
    
    // Close server gracefully
    server.close(() => {
      process.exit(1);
    });
    
    // Force exit after 10s if graceful shutdown fails
    setTimeout(() => {
      process.exit(1);
    }, 10000);
  }
});
```

**Browser Global Handler**:
```javascript
window.addEventListener('unhandledrejection', (event) => {
  console.error('Unhandled Promise Rejection:', event.reason);
  
  // Prevent default browser error handling
  event.preventDefault();
  
  // Log to error tracking service
  if (window.Sentry) {
    Sentry.captureException(event.reason, {
      tags: {
        type: 'unhandled_rejection'
      },
      extra: {
        promise: event.promise,
        timestamp: Date.now()
      }
    });
  }
  
  // Hi·ªÉn th·ªã user-friendly error
  showErrorToast({
    title: 'Something went wrong',
    message: 'We\'re working on fixing this issue.',
    technical: event.reason?.message,
    action: {
      label: 'Retry',
      onClick: () => window.location.reload()
    }
  });
});
```

### 7.2. Structured Error Handling

**Custom Error Classes**:
```javascript
class AsyncError extends Error {
  constructor(message, code, details) {
    super(message);
    this.name = 'AsyncError';
    this.code = code;
    this.details = details;
    this.timestamp = Date.now();
  }
}

class NetworkError extends AsyncError {
  constructor(message, url, status) {
    super(message, 'NETWORK_ERROR', { url, status });
    this.name = 'NetworkError';
  }
}

class ValidationError extends AsyncError {
  constructor(message, field, value) {
    super(message, 'VALIDATION_ERROR', { field, value });
    this.name = 'ValidationError';
  }
}

// Usage
async function fetchWithErrorHandling(url) {
  try {
    const response = await fetch(url);
    
    if (!response.ok) {
      throw new NetworkError(
        'Fetch failed',
        url,
        response.status
      );
    }
    
    return await response.json();
  } catch (error) {
    if (error instanceof NetworkError) {
      // Handle network errors specifically
      logger.error('Network error', error.details);
      throw error;
    }
    
    // Wrap unknown errors
    throw new AsyncError(
      'Unknown error occurred',
      'UNKNOWN_ERROR',
      { url, originalError: error.message }
    );
  }
}
```

### 7.3. Error Boundaries for Async (React)

> **‚ö†Ô∏è L∆∞u √Ω**: React Error Boundaries **kh√¥ng** catch async errors theo m·∫∑c ƒë·ªãnh. C·∫ßn wrapper pattern.

**Async Error Boundary Pattern**:
```javascript
// HOC wrapper cho async operations
function withAsyncErrorBoundary(asyncFn) {
  return async (...args) => {
    try {
      return await asyncFn(...args);
    } catch (error) {
      // Convert async error th√†nh sync error ƒë·ªÉ Error Boundary catch
      throw error;
    }
  };
}

// Usage trong component
function MyComponent() {
  const [data, setData] = useState(null);
  
  const fetchData = withAsyncErrorBoundary(async () => {
    const result = await fetch('/api/data');
    setData(result);
  });
  
  useEffect(() => {
    fetchData().catch(error => {
      // Re-throw ƒë·ªÉ Error Boundary catch
      throw error;
    });
  }, []);
  
  return <div>{data}</div>;
}
```

**Better Pattern: Use Error State**:
```javascript
function MyComponent() {
  const [data, setData] = useState(null);
  const [error, setError] = useState(null);
  
  useEffect(() => {
    async function loadData() {
      try {
        const result = await fetch('/api/data');
        setData(result);
      } catch (err) {
        setError(err);
      }
    }
    
    loadData();
  }, []);
  
  if (error) {
    return <ErrorDisplay error={error} />;
  }
  
  return <div>{data}</div>;
}
```

### 7.4. Production Monitoring

**Error Tracking Services Integration**:

**Sentry**:
```javascript
import * as Sentry from '@sentry/node';

Sentry.init({
  dsn: process.env.SENTRY_DSN,
  environment: process.env.NODE_ENV,
  tracesSampleRate: 1.0,
});

// Capture async errors
async function monitoredFetch(url) {
  const transaction = Sentry.startTransaction({
    op: 'http',
    name: `GET ${url}`,
  });
  
  try {
    const response = await fetch(url);
    transaction.setStatus('ok');
    return response;
  } catch (error) {
    transaction.setStatus('internal_error');
    
    Sentry.captureException(error, {
      tags: { url },
      extra: { timestamp: Date.now() }
    });
    
    throw error;
  } finally {
    transaction.finish();
  }
}
```

**Performance Monitoring**:
```javascript
class PerformanceMonitor {
  static async measure(name, fn) {
    const start = performance.now();
    
    try {
      const result = await fn();
      const duration = performance.now() - start;
      
      console.log(`[${name}] Duration: ${duration.toFixed(2)}ms`);
      
      // Send to analytics
      this.sendMetric(name, duration, 'success');
      
      // Alert if slow
      if (duration > 5000) {
        alertSlowOperation(name, duration);
      }
      
      return result;
    } catch (error) {
      const duration = performance.now() - start;
      
      console.error(`[${name}] Failed after ${duration.toFixed(2)}ms`, error);
      
      this.sendMetric(name, duration, 'error');
      
      throw error;
    }
  }
  
  static sendMetric(name, duration, status) {
    // Send to monitoring service (Datadog, New Relic, etc.)
    if (window.gtag) {
      gtag('event', 'timing_complete', {
        name,
        value: Math.round(duration),
        event_category: 'async_operations',
        event_label: status
      });
    }
  }
}

// Usage
const data = await PerformanceMonitor.measure('fetchUserData', async () => {
  return await fetch('/api/user').then(r => r.json());
});
```

---

## 8. Performance Optimization

### 8.1. Identifying Bottlenecks

**Chrome DevTools Performance Profiler**:
1. Open DevTools ‚Üí Performance tab
2. Record profile while using app
3. Analyze flame chart:
   - **Yellow bars**: Scripting (JavaScript execution)
   - **Purple bars**: Rendering (style calculation, layout)
   - **Green bars**: Painting
   - **Red indicators**: Long tasks (>50ms)

**Long Task API**:
```javascript
const observer = new PerformanceObserver((list) => {
  for (const entry of list.getEntries()) {
    console.warn('Long task detected:', {
      duration: entry.duration,
      startTime: entry.startTime,
      name: entry.name
    });
    
    // Log to monitoring
    if (entry.duration > 100) {
      logLongTask({
        duration: entry.duration,
        timestamp: Date.now()
      });
    }
  }
});

observer.observe({ entryTypes: ['longtask'] });
```

### 8.2. Task Chunking

**Problem**: Long synchronous task blocks event loop

**Solution**: Split v√†o smaller chunks v·ªõi macrotask scheduling

```javascript
// ‚ùå BAD: Blocks UI for entire duration
function processLargeArray(items) {
  const results = [];
  for (const item of items) {
    results.push(expensiveOperation(item));
  }
  return results;
}

// ‚úÖ GOOD: Yields to event loop between chunks
async function processLargeArrayChunked(items, chunkSize = 1000) {
  const results = [];
  
  for (let i = 0; i < items.length; i += chunkSize) {
    const chunk = items.slice(i, i + chunkSize);
    
    for (const item of chunk) {
      results.push(expensiveOperation(item));
    }
    
    // Yield to event loop
    await new Promise(resolve => setTimeout(resolve, 0));
    
    // Update progress
    const progress = ((i + chunkSize) / items.length) * 100;
    updateProgressBar(Math.min(progress, 100));
  }
  
  return results;
}

// Usage
const items = Array.from({ length: 100000 }, (_, i) => i);
const results = await processLargeArrayChunked(items);
```

**Time-slicing with requestIdleCallback** (better cho non-critical work):
```javascript
async function processWhenIdle(items) {
  const results = [];
  let index = 0;
  
  while (index < items.length) {
    await new Promise(resolve => {
      requestIdleCallback((deadline) => {
        // Process while idle time available
        while (deadline.timeRemaining() > 0 && index < items.length) {
          results.push(expensiveOperation(items[index]));
          index++;
        }
        
        resolve();
      });
    });
  }
  
  return results;
}
```

### 8.3. Memoization cho Async Functions

```javascript
function memoizeAsync(fn, options = {}) {
  const cache = new Map();
  const { ttl = Infinity, maxSize = Infinity } = options;
  
  return async function(...args) {
    const key = JSON.stringify(args);
    
    if (cache.has(key)) {
      const { value, timestamp } = cache.get(key);
      
      // Check TTL
      if (Date.now() - timestamp < ttl) {
        return value;
      }
      
      cache.delete(key);
    }
    
    const value = await fn.apply(this, args);
    
    // Enforce max size (LRU)
    if (cache.size >= maxSize) {
      const firstKey = cache.keys().next().value;
      cache.delete(firstKey);
    }
    
    cache.set(key, { 
      value, 
      timestamp: Date.now() 
    });
    
    return value;
  };
}

// Usage
const fetchUser = memoizeAsync(
  async (userId) => {
    const response = await fetch(`/api/users/${userId}`);
    return response.json();
  },
  { 
    ttl: 60000,  // Cache for 1 minute
    maxSize: 100 // Max 100 entries
  }
);

await fetchUser(1); // Fetch from API
await fetchUser(1); // Return from cache (< 1 minute)
```

### 8.4. Lazy Loading

**Code Splitting v·ªõi Dynamic Imports**:
```javascript
// Load heavy library only when needed
async function processImage(image) {
  // Load library dynamically
  const { default: imageProcessor } = await import('./heavy-image-lib.js');
  
  return imageProcessor.process(image);
}

// React lazy loading
const HeavyComponent = React.lazy(() => import('./HeavyComponent'));

function App() {
  return (
    <Suspense fallback={<Loading />}>
      <HeavyComponent />
    </Suspense>
  );
}
```

**Image Lazy Loading**:
```javascript
// Intersection Observer for lazy loading
const imageObserver = new IntersectionObserver((entries) => {
  entries.forEach(entry => {
    if (entry.isIntersecting) {
      const img = entry.target;
      img.src = img.dataset.src; // Load actual image
      imageObserver.unobserve(img);
    }
  });
});

document.querySelectorAll('img[data-src]').forEach(img => {
  imageObserver.observe(img);
});
```

### 8.5. Web Worker Patterns

**Worker Pool**:
```javascript
class WorkerPool {
  constructor(workerScript, poolSize = navigator.hardwareConcurrency || 4) {
    this.workers = [];
    this.queue = [];
    
    // Create worker pool
    for (let i = 0; i < poolSize; i++) {
      const worker = new Worker(workerScript);
      this.workers.push({ worker, busy: false });
    }
  }
  
  async execute(data) {
    return new Promise((resolve, reject) => {
      const task = { data, resolve, reject };
      
      // Try to assign to free worker
      const freeWorker = this.workers.find(w => !w.busy);
      
      if (freeWorker) {
        this.runTask(freeWorker, task);
      } else {
        this.queue.push(task);
      }
    });
  }
  
  runTask(workerObj, task) {
    workerObj.busy = true;
    
    const handleMessage = (e) => {
      workerObj.worker.removeEventListener('message', handleMessage);
      workerObj.worker.removeEventListener('error', handleError);
      workerObj.busy = false;
      
      task.resolve(e.data);
      
      // Process next queued task
      if (this.queue.length > 0) {
        const nextTask = this.queue.shift();
        this.runTask(workerObj, nextTask);
      }
    };
    
    const handleError = (error) => {
      workerObj.worker.removeEventListener('message', handleMessage);
      workerObj.worker.removeEventListener('error', handleError);
      workerObj.busy = false;
      
      task.reject(error);
    };
    
    workerObj.worker.addEventListener('message', handleMessage);
    workerObj.worker.addEventListener('error', handleError);
    workerObj.worker.postMessage(task.data);
  }
  
  terminate() {
    this.workers.forEach(({ worker }) => worker.terminate());
  }
}

// Usage
const pool = new WorkerPool('processor.js', 4);

// Process 100 items across 4 workers
const results = await Promise.all(
  items.map(item => pool.execute(item))
);
```

### 8.6. Core Web Vitals Monitoring

```javascript
// Largest Contentful Paint (LCP)
new PerformanceObserver((list) => {
  const entries = list.getEntries();
  const lastEntry = entries[entries.length - 1];
  
  console.log('LCP:', lastEntry.renderTime || lastEntry.loadTime);
  
  // Send to analytics
  sendMetric('LCP', lastEntry.renderTime || lastEntry.loadTime);
}).observe({ entryTypes: ['largest-contentful-paint'] });

// First Input Delay (FID)
new PerformanceObserver((list) => {
  const entries = list.getEntries();
  
  entries.forEach(entry => {
    console.log('FID:', entry.processingStart - entry.startTime);
    sendMetric('FID', entry.processingStart - entry.startTime);
  });
}).observe({ entryTypes: ['first-input'] });

// Cumulative Layout Shift (CLS)
let clsScore = 0;

new PerformanceObserver((list) => {
  for (const entry of list.getEntries()) {
    if (!entry.hadRecentInput) {
      clsScore += entry.value;
    }
  }
  
  console.log('CLS:', clsScore);
  sendMetric('CLS', clsScore);
}).observe({ entryTypes: ['layout-shift'] });
```

---

## 9. Testing Async Code

### 9.1. Testing Strategies

**Jest/Vitest v·ªõi async/await**:
```javascript
describe('fetchUser', () => {
  it('should fetch user data successfully', async () => {
    const user = await fetchUser(1);
    
    expect(user).toEqual({
      id: 1,
      name: 'John Doe'
    });
  });
  
  it('should handle errors', async () => {
    await expect(fetchUser(999)).rejects.toThrow('User not found');
  });
});
```

**Testing v·ªõi done() callback** (legacy):
```javascript
it('should complete async operation', (done) => {
  fetchUser(1).then(user => {
    expect(user.name).toBe('John Doe');
    done(); // Must call done()
  }).catch(done); // Pass done to catch for errors
});
```

### 9.2. Mocking Async Operations

**Mock Timers**:
```javascript
describe('debounce', () => {
  beforeEach(() => {
    jest.useFakeTimers();
  });
  
  afterEach(() => {
    jest.useRealTimers();
  });
  
  it('should debounce function calls', () => {
    const fn = jest.fn();
    const debounced = debounce(fn, 1000);
    
    debounced();
    debounced();
    debounced();
    
    expect(fn).not.toHaveBeenCalled();
    
    // Fast-forward time
    jest.advanceTimersByTime(1000);
    
    expect(fn).toHaveBeenCalledTimes(1);
  });
});
```

**Mock fetch**:
```javascript
// Using jest-fetch-mock
import fetchMock from 'jest-fetch-mock';

fetchMock.enableMocks();

beforeEach(() => {
  fetch.resetMocks();
});

it('should fetch user data', async () => {
  fetch.mockResponseOnce(JSON.stringify({ id: 1, name: 'John' }));
  
  const user = await fetchUser(1);
  
  expect(fetch).toHaveBeenCalledWith('/api/users/1');
  expect(user).toEqual({ id: 1, name: 'John' });
});

it('should handle fetch errors', async () => {
  fetch.mockReject(new Error('Network error'));
  
  await expect(fetchUser(1)).rejects.toThrow('Network error');
});
```

**Mock v·ªõi MSW (Mock Service Worker)** - More realistic:
```javascript
import { rest } from 'msw';
import { setupServer } from 'msw/node';

const server = setupServer(
  rest.get('/api/users/:id', (req, res, ctx) => {
    return res(
      ctx.json({ id: req.params.id, name: 'John Doe' })
    );
  })
);

beforeAll(() => server.listen());
afterEach(() => server.resetHandlers());
afterAll(() => server.close());

it('should fetch user', async () => {
  const user = await fetchUser(1);
  expect(user.name).toBe('John Doe');
});
```

### 9.3. Testing Race Conditions

```javascript
describe('race condition handling', () => {
  it('should only use latest request result', async () => {
    let currentController;
    const results = [];
    
    async function search(query) {
      if (currentController) {
        currentController.abort();
      }
      
      currentController = new AbortController();
      
      try {
        const response = await fetch(`/api/search?q=${query}`, {
          signal: currentController.signal
        });
        results.push(await response.json());
      } catch (error) {
        if (error.name !== 'AbortError') throw error;
      }
    }
    
    // Trigger multiple searches
    search('a');
    search('ab');
    await search('abc');
    
    // Only last search result should be present
    expect(results).toHaveLength(1);
    expect(results[0].query).toBe('abc');
  });
});
```

### 9.4. Testing Async Generators

```javascript
describe('async generator', () => {
  it('should yield all values', async () => {
    async function* generate() {
      yield 1;
      yield 2;
      yield 3;
    }
    
    const values = [];
    for await (const value of generate()) {
      values.push(value);
    }
    
    expect(values).toEqual([1, 2, 3]);
  });
  
  it('should handle errors in generator', async () => {
    async function* generateWithError() {
      yield 1;
      throw new Error('Generator error');
    }
    
    const values = [];
    
    await expect(async () => {
      for await (const value of